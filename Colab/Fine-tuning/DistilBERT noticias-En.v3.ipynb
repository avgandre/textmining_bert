{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DistilBERT noticias-En.v3.ipynb","provenance":[{"file_id":"1bBUl2PzKUQhxtSMWT5dBBP1TfUXTPiGn","timestamp":1648151540959},{"file_id":"1fdrMllG1VFwVkJHG0Vga6lWrgku7BkH7","timestamp":1635278334779},{"file_id":"1j-THdgLf_XOhZvZ0auTN6i9CIARPrvsl","timestamp":1635210983576},{"file_id":"1R7fLhT28aLu4M7CJuIblmqrnO6gxMZFd","timestamp":1634921059710},{"file_id":"1Qz6QIcAsaFKlHcJtwcGZhmRTqMg8hz8e","timestamp":1634901366570}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"2E5dZcv_mv5t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648411400511,"user_tz":180,"elapsed":13508,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"a2e91f7e-dc5c-48f7-e5e1-dfd4b070c77d"},"source":["!pip install transformers"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","metadata":{"id":"KbF_ZxV5mzfG","executionInfo":{"status":"ok","timestamp":1648411409645,"user_tz":180,"elapsed":9156,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["import torch\n","import numpy as np\n","import pandas as pd\n","import time\n","import re\n","from random import sample\n","\n","from sklearn.model_selection import train_test_split"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"-RIluI2lo0D6","executionInfo":{"status":"ok","timestamp":1648411409647,"user_tz":180,"elapsed":40,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["#Tempo de processamento\n","tempoInicial = time.time()\n","\n","#Faz a leitura da base\n","df = pd.read_csv('dataset7DiasCompleto-En.v1.csv', sep=';')\n","df.describe()\n","\n","colunaCorpus='titulo_processado'\n","colunaResultado='classe'"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"qq_ROpFgo-CH","executionInfo":{"status":"ok","timestamp":1648411409649,"user_tz":180,"elapsed":35,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["randomState = sample(range(0, 1000), 1)[0];\n","\n","#Definindo X, y\n","X = df[df.columns.difference([colunaResultado])]\n","y = df[colunaResultado]\n","\n","#Separa base treinamento e teste\n","XTreino, XTeste, yTreino, yTeste = train_test_split(X, y, train_size=0.7, \n","                                                    stratify=y, shuffle=True, \n","                                                    random_state=randomState)\n","XTreino = XTreino[colunaCorpus].values\n","yTreino = yTreino.values\n","XTeste = XTeste[colunaCorpus].values\n","yTeste = yTeste.values"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"TO984qUu6EJE","executionInfo":{"status":"ok","timestamp":1648411412929,"user_tz":180,"elapsed":3303,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["import transformers\n","\n","## distil-bert tokenizer\n","tokenizer = transformers.AutoTokenizer.from_pretrained('distilbert-base-uncased', do_lower_case=True)"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"FSg_B1tGpBoX","executionInfo":{"status":"ok","timestamp":1648411412931,"user_tz":180,"elapsed":27,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["corpus = XTreino\n","#corpus = XTreino[colunaCorpus]\n","maxlen = 512"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y012tkgpXIT0","executionInfo":{"status":"ok","timestamp":1648411415248,"user_tz":180,"elapsed":2341,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"48e8d0d7-2881-4c5e-9a49-20283d0a89c9"},"source":["def tokenize(sentences, tokenizer):\n","    input_ids, input_masks, input_segments = [],[],[]\n","    for s in range(len(sentences)):\n","        sentence = sentences[s]\n","        inputs = tokenizer.encode_plus(sentence, add_special_tokens=True, max_length=512, pad_to_max_length=True, \n","                                             return_attention_mask=True, return_token_type_ids=True)\n","        input_ids.append(inputs['input_ids'])\n","        input_masks.append(inputs['attention_mask'])\n","        input_segments.append(inputs['token_type_ids'])        \n","        \n","    return np.asarray(input_ids, dtype='int32'), np.asarray(input_masks, dtype='int32')\n","\n","X = tokenize(corpus, tokenizer)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B_sisVlW6mmF","executionInfo":{"status":"ok","timestamp":1648411438881,"user_tz":180,"elapsed":23652,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"7fddec5c-ce88-4983-d477-7939a5ca76d5"},"source":["import tensorflow as tf\n","from transformers import TFDistilBertModel, DistilBertConfig\n","\n","## inputs\n","input_ids_in = tf.keras.layers.Input(shape=(512,), name='input_token', dtype='int32')\n","input_masks_in = tf.keras.layers.Input(shape=(512,), name='masked_token', dtype='int32') \n","\n","## pre-trained bert with config\n","transformer_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased', output_hidden_states = False)\n","bert_out = transformer_model(input_ids_in, attention_mask=input_masks_in)[0]\n","\n","## fine-tuning\n","x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, return_sequences=True, dropout=0.1, recurrent_dropout=0.1))(bert_out)\n","x = tf.keras.layers.GlobalMaxPool1D()(x)\n","x = tf.keras.layers.Dense(50, activation='relu')(x)\n","x = tf.keras.layers.Dropout(0.2)(x)\n","x = tf.keras.layers.Dense(len(np.unique(yTreino)), activation='sigmoid')(x)\n","model = tf.keras.Model(inputs=[input_ids_in, input_masks_in], outputs = x)\n","\n","for layer in model.layers[:3]:\n","    layer.trainable = False\n","\n","model.compile(loss='sparse_categorical_crossentropy', \n","              optimizer='adam', metrics=['accuracy'])\n","model.summary()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["Some layers from the model checkpoint at distilbert-base-uncased were not used when initializing TFDistilBertModel: ['vocab_transform', 'vocab_layer_norm', 'vocab_projector', 'activation_13']\n","- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFDistilBertModel were initialized from the model checkpoint at distilbert-base-uncased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_token (InputLayer)       [(None, 512)]        0           []                               \n","                                                                                                  \n"," masked_token (InputLayer)      [(None, 512)]        0           []                               \n","                                                                                                  \n"," tf_distil_bert_model (TFDistil  TFBaseModelOutput(l  66362880   ['input_token[0][0]',            \n"," BertModel)                     ast_hidden_state=(N               'masked_token[0][0]']           \n","                                one, 512, 768),                                                   \n","                                 hidden_states=None                                               \n","                                , attentions=None)                                                \n","                                                                                                  \n"," bidirectional (Bidirectional)  (None, 512, 200)     695200      ['tf_distil_bert_model[0][0]']   \n","                                                                                                  \n"," global_max_pooling1d (GlobalMa  (None, 200)         0           ['bidirectional[0][0]']          \n"," xPooling1D)                                                                                      \n","                                                                                                  \n"," dense (Dense)                  (None, 50)           10050       ['global_max_pooling1d[0][0]']   \n","                                                                                                  \n"," dropout_19 (Dropout)           (None, 50)           0           ['dense[0][0]']                  \n","                                                                                                  \n"," dense_1 (Dense)                (None, 5)            255         ['dropout_19[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 67,068,385\n","Trainable params: 705,505\n","Non-trainable params: 66,362,880\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","metadata":{"id":"A7aBe0r5972d","colab":{"base_uri":"https://localhost:8080/"},"outputId":"fb1e8378-3c61-40f7-b341-ed8575a9e13c","executionInfo":{"status":"ok","timestamp":1648418192935,"user_tz":180,"elapsed":6754063,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["## encode y\n","#dic_y_mapping = {n:label for n,label in \n","#                 enumerate(np.unique(yTreino))}\n","#inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n","#yTreino = np.array([inverse_dic[y] for y in yTreino])\n","\n","## train\n","training = model.fit(x=X, y=yTreino, batch_size=128, epochs=1, shuffle=True, \n","                     verbose=1, validation_split=0.2)"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["38/38 [==============================] - 6712s 176s/step - loss: 0.8138 - accuracy: 0.7118 - val_loss: 0.5176 - val_accuracy: 0.8174\n"]}]},{"cell_type":"code","metadata":{"id":"BVWo4h_sMdbc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648418193374,"user_tz":180,"elapsed":467,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"a52c9699-8daf-4b43-d6cb-53ecc52f82e7"},"source":["corpus = XTeste\n","X = tokenize(corpus, tokenizer)"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2277: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  FutureWarning,\n"]}]},{"cell_type":"code","metadata":{"id":"UavXNHicMfCn","executionInfo":{"status":"ok","timestamp":1648420479053,"user_tz":180,"elapsed":2285691,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}}},"source":["## test\n","predicted_prob = model.predict(X)\n","predicted = [np.argmax(pred) for pred in predicted_prob]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2hjEq4WMhor","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648420479058,"user_tz":180,"elapsed":55,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"67b5dd4b-8810-40c8-a252-927b793106bb"},"source":["from sklearn.metrics import classification_report\n","\n","print(classification_report(yTeste, predicted, labels=[0, 1, 2, 3, 4]))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       0.88      0.76      0.82       452\n","           1       0.72      0.82      0.77       629\n","           2       0.81      0.81      0.81       645\n","           3       0.84      0.78      0.80       600\n","           4       0.76      0.81      0.78       268\n","\n","    accuracy                           0.80      2594\n","   macro avg       0.80      0.80      0.80      2594\n","weighted avg       0.80      0.80      0.80      2594\n","\n"]}]},{"cell_type":"code","source":["print(\"\\n--- %.2f minutos ---\" % ((time.time() - tempoInicial) / 60))"],"metadata":{"id":"mkgJ-cpjGV6p","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648420479060,"user_tz":180,"elapsed":44,"user":{"displayName":"Andre Vinicius Goncalves andre.goncalves","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13983450635099186300"}},"outputId":"983f434a-5700-4427-f528-caeb864839ba"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","--- 151.16 minutos ---\n"]}]}]}